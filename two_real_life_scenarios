#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Run two real-life scenarios with CV-estimated (α, β) and outer k₁ search
======================================================================

Scenario-1 : synthetic Normal(2, 1²), n=200
Scenario-2 : course-completion rate (bounded [0,1]), n=200
"""

import math
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from sklearn.model_selection import KFold

# ---------- 共用工具 --------------------------------------------------
def mse(y, pred): return ((y - pred) ** 2).mean()

def tl_ll_mu(x):
    mu, sig = x.mean(), x.std(ddof=1)
    if sig < 1e-14: return -1e15, mu
    ll = -0.5 * len(x) * math.log(2*math.pi*sig**2) - ((x-mu)**2).sum()/(2*sig**2)
    return ll, mu

def el_ll_mu(x, max_iter=200):
    n, yb = len(x), x.mean()
    def g(L):
        d = 1 + L*(x-yb)
        return np.inf if np.any(d<=0) else (1/d).sum() - n
    if abs(g(0)) < 1e-8:
        return -n*math.log(n), yb
    a, b = -1e4, 1e4
    if g(a)*g(b) > 0: return -1e15, yb
    for _ in range(max_iter):
        m  = 0.5*(a+b); gm = g(m)
        if abs(gm) < 1e-8: break
        if g(a)*gm < 0: b = m
        else:            a = m
    lam = 0.5*(a+b)
    d = 1 + lam*(x-yb)
    if np.any(d<=0): return -1e15, yb
    ll = (-np.log(n*d)).sum()
    return ll, yb

def cv_choose_alpha_beta(y_true,
                         gen_model, gen_obs,
                         grid=(0,0.2,0.4,0.6,0.8,1),
                         k=5, seed=2023):
    kf = KFold(n_splits=k, shuffle=True, random_state=seed)
    best, best_ab = 1e18, (None, None)
    for a in grid:
        for b in grid:
            errs=[]
            for tr,val in kf.split(y_true):
                y_tr, y_val = y_true[tr], y_true[val]
                ytl = gen_model(y_tr, a, seed=111)
                yel = gen_obs( y_tr, b, seed=222)
                _, mu_tl = tl_ll_mu(ytl)
                _, mu_el = el_ll_mu(yel)
                errs.append(min(mse(y_val, mu_tl), mse(y_val, mu_el)))
            err = np.mean(errs)
            if err < best:
                best, best_ab = err, (a, b)
    return best_ab, best

# ---------- Scenario-1  ----------------------------------------------
def scenario1():
    print("# === Scenario-1 : Normal(μ=2, σ=1) ===")
    rng = np.random.default_rng(9999)
    y_true = rng.normal(2.0, 1.0, 200)
    true_mu = y_true.mean()
    print(f"True mean ≈ {true_mu:.4f}")

    # 数据生成规则
    def gen_model(y, a, seed):
        rng = np.random.default_rng(seed)
        return y + 0.3*a + rng.normal(0, 0.2*(1-a), len(y))
    def gen_obs(y, b, seed):
        rng = np.random.default_rng(seed)
        return y - 0.2*b + rng.normal(0, 0.2*(1-b), len(y))

    (alpha,beta), cv_mse = cv_choose_alpha_beta(y_true, gen_model, gen_obs)
    print(f"CV α={alpha:.1f}, β={beta:.1f}  (CV-MSE={cv_mse:.4f})")

    ytl = gen_model(y_true, alpha, seed=333)
    yel = gen_obs( y_true, beta,  seed=444)
    _, mu_tl = tl_ll_mu(ytl)
    _, mu_el = el_ll_mu(yel)
    print(f"μ_TL={mu_tl:.4f}  μ_EL={mu_el:.4f}")

    # outer weight (raw μ; 不再乘 α,β)
    best_k1,best_mse = 0,1e18
    for k1 in np.linspace(0,1,101):
        pred = k1*mu_tl + (1-k1)*mu_el
        cur  = mse(y_true, pred)
        if cur < best_mse:
            best_k1, best_mse = k1, cur
    fused_pred = best_k1*mu_tl + (1-best_k1)*mu_el
    print(f"Fused k1={best_k1:.2f}  μ={fused_pred:.4f}  MSE={best_mse:.4f}\n")

    # hist
    plt.figure(figsize=(6,4))
    plt.hist(y_true, bins=30, color="pink", edgecolor="k", alpha=.85)
    plt.axvline(true_mu, color="r", lw=2, label=f"True μ {true_mu:.3f}")
    plt.title("Scenario 1 Histogram")
    plt.legend(); plt.tight_layout()
    plt.savefig("fig_scenario1_hist.png", dpi=300)

# ---------- Scenario-2  ----------------------------------------------
def scenario2():
    print("# === Scenario-2 : Completion-rate data ===")
    rng = np.random.default_rng(123)
    y_true = np.clip(rng.normal(0.61, 0.15, 200), 0, 1)
    true_mu = y_true.mean()
    print(f"True mean ≈ {true_mu:.4f}")

    # 调校后规则
    def gen_model(y, a, seed):
        rng = np.random.default_rng(seed)
        return y + 0.12*a + rng.normal(0, 0.03*(1-a), len(y))
    def gen_obs(y, b, seed):
        rng = np.random.default_rng(seed)
        return y - 1.00*b + rng.normal(0, 0.08*(1-b), len(y))

    (alpha,beta), cv_mse = cv_choose_alpha_beta(y_true, gen_model, gen_obs)
    print(f"CV α={alpha:.1f}, β={beta:.1f}  (CV-MSE={cv_mse:.4f})")

    ytl = gen_model(y_true, alpha, seed=333)
    yel = gen_obs( y_true, beta,  seed=444)
    _, mu_tl = tl_ll_mu(ytl)
    _, mu_el = el_ll_mu(yel)
    print(f"μ_TL={mu_tl:.4f}  μ_EL={mu_el:.4f}")

    best_k1,best_mse = 0,1e18
    for k1 in np.linspace(0,1,101):
        pred = k1*mu_tl + (1-k1)*mu_el
        cur  = mse(y_true, pred)
        if cur < best_mse:
            best_k1, best_mse = k1, cur
    fused_pred = best_k1*mu_tl + (1-best_k1)*mu_el
    print(f"Fused k1={best_k1:.2f}  μ={fused_pred:.4f}  MSE={best_mse:.4f}\n")

    # hist
    plt.figure(figsize=(6,4))
    plt.hist(y_true, bins=30, color="skyblue", edgecolor="k", alpha=.85)
    plt.axvline(true_mu, color="r", lw=2, label=f"True μ {true_mu:.3f}")
    plt.title("Scenario 2 Histogram")
    plt.legend(); plt.tight_layout()
    plt.savefig("fig_completion_hist_s2.png", dpi=300)

# ---------- main ------------------------------------------------------
if __name__ == "__main__":
    Path(".").mkdir(exist_ok=True)
    scenario1()
    scenario2()
